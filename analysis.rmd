---
title: "Consumer Complaints Analysis"
author: "Evan Miller"
date: "Saturday, April 30, 2016"
output:
  html_document:
    toc: true
---

Hey all,

Sometimes I can get on my high horse saying "who needs SQL, I can do all that and more in R/Python!". That being said, SQL is pretty great at what it does. It might not have all the fancy packages that R has but heck it's been around for a long time, and it isn't going away any time soon. 

This post is a compromise. I wanna see how the other side of Business Intelligence lives (in SQL land) while maybe helping some more conventional BI devs see that that R isn't as terrifying as it's made out to be.

So here I'll go through and do my code two ways:

- First using dplyr
- Second converting that dplyr to SQL

Hopefully this shouldn't be too difficult. But I could be over-estimating my SQL skills.

This dataset should hopefully be really good for using a SQL based approach, because it's kinda big!

## 1. Loading libraries and getting a feel for the data

```{r, libraries, message=FALSE}
library(dplyr)
library(RSQLite)
library(DT)
library(ggplot2)
library(ggthemes)
library(scales)
library(lubridate)
```

```{r, connect_SQL}

basepath <- 'C:/Users/evanm_000/Desktop/Work/Consumer Finance'
setwd(basepath)

conn <- dbConnect(SQLite(), "database.sqlite")
#system("ls ../input")
#conn <- dbConnect(SQLite(), "database.sqlite")

tbls <- dbListTables(conn)

```


First we'll open the connection to the data. Sadly for dplyr I'll need to keep it in memory.
The database has only one table:

- `r tbls[1]`

First question, what does the data look like?

```{r, echo=FALSE}

data <- dbGetQuery(conn, "SELECT *
                          FROM consumer_complaints")

str(data)
```

## 2. Starting small - looking at the top five tows

Next we'll do a suuuuper simple query by just looking at the top 5 rows to get a bit more context. I'll check that the results are identical before showing the results.

```{r, first_obs}

head_dplyr <- data %>%
                   slice(1:5)

head_sql <- dbGetQuery(conn, "SELECT * 
                            FROM consumer_complaints 
                            LIMIT 5")

equal <- identical(head_dplyr, head_sql)

datatable(head_sql, class="compact")

```

#### Are the two tables equal? `r equal` !!
Nailed it. 

But let's be honest, that's possibly the second most simple SQL query written in human history (a bit harder than SELECT *) so let's try out some more complex queries. 

## 3. Getting a bit more fancy - the 10 most common companies to complain against


```{r, group_by_company}

group_comp_dplyr <- data %>%
                    group_by(company) %>%
                    summarise(count = n()) %>%
                    arrange(desc(count)) %>%
                    slice(1:10)

group_comp_sql <- dbGetQuery(conn, "SELECT COMPANY, COUNT(*) as count 
                                    FROM consumer_complaints
                                    GROUP BY COMPANY
                                    ORDER BY count DESC
                                    LIMIT 10")

equal <- identical(group_comp_dplyr, tbl_df(group_comp_sql))

g <- ggplot(group_comp_dplyr, aes(y = count, x = reorder(company, count))) + geom_bar(stat="identity")
g1 <- g + coord_flip() + theme_fivethirtyeight() + scale_y_continuous(labels = comma, limits = c(0, 60000)) + 
      ggtitle("The most popular companies to file complaints against are..")

g1 + theme(plot.title = element_text(size = rel(0.8)))
```


#### But are the two tables equal? `r equal` !!
Woo, we're getting better at this..

## 4. Working with dates

In this section I'll work at using dates to summarise data. You'll see that I had to do a bit of hacking in this section as the date received variable doesn't seem to be in SQLite acceptable format (I might be wrong, but have a look here anyway https://www.sqlite.org/lang_datefunc.html)

So it's unideal and no one likes to just make a point solution, but I really can't be bothered re-compiling a new SQLite datebase. So here we go!

```{r, yearsum}

data <- data   %>%
        mutate(date_received = mdy(date_received),
               year = year(date_received))

year_compaints_dplyr <- data %>%
                    group_by(year) %>%
                    summarise(count = n())

year_compaints_sql <- dbGetQuery(conn, "SELECT substr(DATE_RECEIVED, 7, 10) + 00000 as year, COUNT(*) as count
                                    FROM consumer_complaints
                                    GROUP BY year") %>%
                      mutate(year = as.numeric(year))

equal <- identical(year_compaints_dplyr, tbl_df(year_compaints_sql))

g <- ggplot(year_compaints_dplyr, aes(y = count, year)) + geom_bar(stat="identity") + 
     theme_fivethirtyeight() + scale_y_continuous(labels = comma, limits = c(0, 200000)) + 
     ggtitle("Total complaints over time") + scale_x_continuous(breaks=seq(2011, 2016, 1))

g
```

#### But are the two tables equal? `r equal` !!

## 5. Top companies over time

So in this section I'll take what we did in the earlier section and take it a bit further. We'll take the top four companies in total complaints overall and investigate their complaints over time. 

This section took much longer than I thought it would, my lack of SQL skills knows no bounds.

```{r, comp_time}

comps_top_four <- group_comp_dplyr %>%
                  slice(1:4) %>%
                  select(company) %>%
                  as.matrix

year_compaints_dplyr_comp <- data %>%
                             filter(company %in% comps_top_four) %>%
                             group_by(year, company) %>%
                             summarise(count = n()) %>%
                             ungroup

year_complaints_sql <- dbGetQuery(conn, "SELECT substr(tbl2.DATE_RECEIVED, 7, 10) + 00000 as year, tbl1.company as company, COUNT(*) as count
                                        FROM 
                                        (
                                          SELECT COMPANY as company, COUNT(*) as count
                                          FROM consumer_complaints
                                          GROUP BY company
                                          ORDER BY count DESC
                                          LIMIT 4
                                        ) as tbl1
                                        LEFT JOIN consumer_complaints as tbl2
                                        ON tbl1.company = tbl2.COMPANY
                                        GROUP BY year, tbl1.company
                                        ORDER BY year, tbl1.company"
) %>%
  mutate(year = as.numeric(year))


equal <- identical(tbl_df(year_complaints_sql), year_compaints_dplyr_comp)

g <- ggplot(year_compaints_dplyr_comp, aes(y = count, x = year)) + geom_bar(stat = "identity") +
     theme_fivethirtyeight() + scale_y_continuous(labels = comma, limits = c(0, 20000))

g + ggtitle("Total complaints over time - \nTop four companies to complain against") +      
  scale_x_continuous(breaks=seq(2011, 2016, 1)) + facet_wrap(~company)

```

#### But are the tables the same? (`r equal`, yep)

## 6. The most popular days to complain against the Bank of America

I thought this might be a good SQL statement to look at. 

Sadly you'll see that my choice to regard received_date as a character really comes back to haunt me in this section as the ordering doesn't work properly within the SQL statement, meaning I've got to bring in some dplyr magic to fix my mistake.

Please, learn from my mistakes!

```{r, complain_BoA}

top_days_dplyr_comp_boa <- data %>%
                           filter(company == 'Bank of America') %>%
                           group_by(date_received) %>%
                           summarise(count = n()) %>%
                           ungroup %>%
                           top_n(10, count) %>%
                           arrange(desc(count), desc(date_received))

top_days_sql_comp_boa <- dbGetQuery(conn, "SELECT date_received, COUNT(*) as count
                                        FROM consumer_complaints
                                        WHERE company = 'Bank of America'
                                        GROUP BY date_received
                                        ORDER BY count DESC
                                        LIMIT 10") %>%
                                        mutate(date_received = mdy(date_received)) %>%
                                        arrange(desc(count), desc(date_received))


equal <- identical(tbl_df(top_days_sql_comp_boa), top_days_dplyr_comp_boa)

g <- ggplot(top_days_dplyr_comp_boa, aes(y = count, x = reorder(date_received, count))) + geom_bar(stat = "identity") + coord_flip()
g1 <- g + theme_fivethirtyeight() + ggtitle("Top 10 days to complain against BoA") + scale_y_continuous(limits = c(0, 200))

g1
```

Are the tables the same? `r equal`!! 
If I could create a new table within the SQLite database this would've been so easy, but I'm pretty sure I only get read-only access to it.  

This one is definitely the most unsatsifying of all the statements I've looked at

## 7. HALP!!!!!

Yes, Mr/Mrs/Ms/Somewhere on the spectrum - I'm talking to you.

So I've actually run out of ideas. Such a lame way to end a post, I know.. 
But I was thinking, maybe you've got an idea of something that I should look at/do?

These request could come in the format of:

- A cool thing I should look at - such as find the most popular day to lay a complaint against the Bank of America (lols totally taking that one)
- Or a something you know how to do in SQL/dplyr, but you want to know how to do it the other way?

And if I cover it I'll mention you in my post (only if that's OK with you of course).

Otherwise have an epic day,

Miller out.